<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Shape Recognition</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <style>
        body {
            margin: 0;
            padding: 0;
            font-family: 'Arial', sans-serif;
            background: black;
            color: #eaeaea;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            position: relative;
            transition: background 0.5s ease-in-out;
        }
        h1 {
            font-size: 2em;
            font-weight: bold;
            margin-bottom: 20px;
        }
        .video-container {
            position: relative;
            width: 50%;
            max-width: 600px;
            aspect-ratio: 4 / 3;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.5);
            margin-bottom: 30px;
        }
        video, canvas {
            position: absolute;
            width: 100%;
            height: 100%;
        }
        .result {
            font-size: 1.4em;
            font-weight: bold;
            text-align: center;
        }
        .subheading {
            position: absolute;
            bottom: 10px;
            right: 20px;
            font-size: 1em;
            font-weight: bold;
            color: #eaeaea;
        }
    </style>
</head>
<body>
    <h1>Face Shape Recognition</h1>
    <div class="video-container">
        <video id="webcam" autoplay playsinline></video>
        <canvas id="canvas"></canvas>
    </div>
    <div class="result" id="faceShapeResult">Detecting...</div>
    <div class="subheading">Website by Prem Patel</div>

    <script>
        let video = document.getElementById('webcam');
        let canvas = document.getElementById('canvas');
        let ctx = canvas.getContext('2d');
        let resultText = document.getElementById('faceShapeResult');
        let faceMesh;

        async function startWebcam() {
            let stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            return new Promise(resolve => {
                video.onloadedmetadata = () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    resolve();
                };
            });
        }

        async function loadFaceMesh() {
            faceMesh = new FaceMesh({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}` });
            faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.9, minTrackingConfidence: 0.9 });
            faceMesh.onResults(processResults);
        }

        async function detectFace() {
            if (!faceMesh) return;
            await faceMesh.send({ image: video });
            requestAnimationFrame(detectFace);
        }

        function processResults(results) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            if (!results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {
                resultText.innerText = "No Face Detected";
                document.body.style.background = "black";
                return;
            }
            
            let landmarks = results.multiFaceLandmarks[0];
            let faceShape = classifyFaceShape(landmarks);
            resultText.innerText = `Face Shape: ${faceShape}`;
            changeBackgroundColor(faceShape);
        }

        function classifyFaceShape(landmarks) {
            let foreheadWidth = Math.abs(landmarks[10].x - landmarks[338].x);
            let cheekboneWidth = Math.abs(landmarks[234].x - landmarks[454].x);
            let jawWidth = Math.abs(landmarks[152].x - landmarks[175].x);
            let faceHeight = Math.abs(landmarks[10].y - landmarks[152].y);
            
            let aspectRatio = cheekboneWidth / faceHeight;
            
            if (aspectRatio > 1.3) return "Oval";
            if (jawWidth > cheekboneWidth * 1.1) return "Square";
            if (cheekboneWidth > foreheadWidth * 1.2) return "Heart";
            if (aspectRatio < 0.9) return "Round";
            if (faceHeight > foreheadWidth * 1.6) return "Oblong";
            if (jawWidth > cheekboneWidth && cheekboneWidth > foreheadWidth) return "Diamond";
            if (jawWidth > foreheadWidth * 1.15) return "Pear";
            return "Unknown";
        }

        function changeBackgroundColor(faceShape) {
            const colors = {
                "Diamond": "blue",
                "Heart": "red",
                "Oval": "green",
                "Square": "yellow",
                "Round": "purple",
                "Oblong": "orange",
                "Pear": "pink"
            };
            document.body.style.background = colors[faceShape] || "black";
        }

        async function run() {
            await startWebcam();
            await loadFaceMesh();
            detectFace();
        }

        run();
    </script>
</body>
</html>
